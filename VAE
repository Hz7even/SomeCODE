import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# 定义VAE模型
class VAE(nn.Module):
    def __init__(self, input_size, hidden_size, latent_size):
        super(VAE, self).__init__()

        self.encoder = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, latent_size * 2)  # 输出均值和方差
        )

        self.decoder = nn.Sequential(
            nn.Linear(latent_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, input_size),
            nn.Sigmoid()  # 最后一层使用 Sigmoid 函数输出，因为输入是 0 到 1 的像素值
        )

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x):
        # 编码
        enc_output = self.encoder(x)
        mu, logvar = torch.chunk(enc_output, 2, dim=1)
        z = self.reparameterize(mu, logvar)

        # 解码
        dec_output = self.decoder(z)

        return dec_output, mu, logvar


# 损失函数
def loss_function(recon_x, x, mu, logvar):
    BCE = nn.BCELoss(reduction='sum')(recon_x, x)
    # KL 散度项
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())

    return BCE + KLD


# 数据加载
transform = transforms.Compose([transforms.ToTensor()])
mnist_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
dataloader = DataLoader(mnist_dataset, batch_size=64, shuffle=True)


# 初始化模型、优化器
input_size = 784  # MNIST 图像大小为 28x28，所以输入大小为 784
hidden_size = 256   # 隐藏层大小
latent_size = 20    # 潜在空间的维度
vae = VAE(input_size, hidden_size, latent_size)
optimizer = optim.Adam(vae.parameters(), lr=0.001)


# 训练过程
num_epochs = 10
for epoch in range(num_epochs):
    for data in dataloader:
        inputs, _ = data
        inputs = inputs.view(inputs.size(0), -1)
        inputs = Variable(inputs)

        # 正向传播
        optimizer.zero_grad()
        recon_batch, mu, logvar = vae(inputs)

        # 计算损失
        loss = loss_function(recon_batch, inputs, mu, logvar)

        # 反向传播和优化
        loss.backward()
        optimizer.step()
